{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sanvika25/implemented-Gradient-Descent-strategies-to-train-NN-like-Batch-Stochastic-Mini-Batch-/blob/main/ann_week9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oeQD9wPsEoaD"
      },
      "outputs": [],
      "source": [
        "# Load Data from sklearn package\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('/content/Iris.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:,:5].values\n",
        "y = df.iloc[:,-1].values"
      ],
      "metadata": {
        "id": "kKcVWWxoFXpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prepare Feature Standardization\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, optimizers\n",
        "import tensorflow as tf\n",
        "#One hot encoding\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(sparse_output = False,categories = 'auto')\n",
        "y_encoded = enc.fit_transform(y.reshape(-1,1))\n",
        "\n",
        "# apply train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size = 0.2, random_state = 1)\n",
        "\n",
        "#y_enc = enc.transform(np.array(y_test).reshape(-1,1)) # Need to one-hot encode output for the neuralnetwork output layer\n",
        "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
        "normalizer.adapt(X_train)"
      ],
      "metadata": {
        "id": "H9DRAbWaFZLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Test_loss = []\n",
        "Test_accuracy = []\n",
        "Train_loss = []\n",
        "Train_accuracy = []"
      ],
      "metadata": {
        "id": "lKhHpkV3FaTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "# Generate some random data for demonstration\n",
        "np.random.seed(0)\n",
        "X = np.random.rand(100, 2)\n",
        "y = 2 * X[:, 0] + 3 * X[:, 1] + np.random.rand(100)\n",
        "\n",
        "# Create a simple neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(1, input_dim=2, activation='linear'))\n",
        "\n",
        "# Compile the model with SGD optimizer\n",
        "sgd = SGD(learning_rate=0.01)  # You can adjust the learning rate\n",
        "model.compile(optimizer=sgd, loss='mean_squared_error')\n",
        "\n",
        "# Train the model using SGD\n",
        "model.fit(X, y, epochs=100, batch_size=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X, y)\n",
        "print(f\"Final loss: {loss:.4f}\")\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(X)\n",
        "\n",
        "# Print some predictions\n",
        "for i in range(10):\n",
        "    print(f\"Input: {X[i]}, Target: {y[i]:.2f}, Predicted: {predictions[i][0]:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsdOGXrHFb6C",
        "outputId": "fbdb2455-db4f-4952-8b05-920dafae5edb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - 1s 1ms/step - loss: 3.8664\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.6932\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.5860\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.4932\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.4178\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.3578\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2997\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2633\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2375\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.2129\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.1903\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.1706\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.1571\n",
            "Epoch 14/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.1463\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.1349\n",
            "Epoch 16/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.1267\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.1224\n",
            "Epoch 18/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.1166\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.1125\n",
            "Epoch 20/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.1088\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.1053\n",
            "Epoch 22/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.1034\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.1008\n",
            "Epoch 24/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0997\n",
            "Epoch 25/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0983\n",
            "Epoch 26/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0955\n",
            "Epoch 27/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0957\n",
            "Epoch 28/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0958\n",
            "Epoch 29/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0933\n",
            "Epoch 30/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0943\n",
            "Epoch 31/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0935\n",
            "Epoch 32/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0939\n",
            "Epoch 33/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0924\n",
            "Epoch 34/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0916\n",
            "Epoch 35/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0929\n",
            "Epoch 36/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0930\n",
            "Epoch 37/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0917\n",
            "Epoch 38/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0925\n",
            "Epoch 39/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0909\n",
            "Epoch 40/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0921\n",
            "Epoch 41/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0927\n",
            "Epoch 42/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0927\n",
            "Epoch 43/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0922\n",
            "Epoch 44/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0919\n",
            "Epoch 45/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0923\n",
            "Epoch 46/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0916\n",
            "Epoch 47/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0928\n",
            "Epoch 48/100\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.0924\n",
            "Epoch 49/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0918\n",
            "Epoch 50/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0918\n",
            "Epoch 51/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0915\n",
            "Epoch 52/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0920\n",
            "Epoch 53/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0925\n",
            "Epoch 54/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0920\n",
            "Epoch 55/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0921\n",
            "Epoch 56/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0921\n",
            "Epoch 57/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0924\n",
            "Epoch 58/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0913\n",
            "Epoch 59/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0920\n",
            "Epoch 60/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0927\n",
            "Epoch 61/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0916\n",
            "Epoch 62/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0921\n",
            "Epoch 63/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0917\n",
            "Epoch 64/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0924\n",
            "Epoch 65/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0919\n",
            "Epoch 66/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0921\n",
            "Epoch 67/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0923\n",
            "Epoch 68/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0923\n",
            "Epoch 69/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0921\n",
            "Epoch 70/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0917\n",
            "Epoch 71/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0921\n",
            "Epoch 72/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0917\n",
            "Epoch 73/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0918\n",
            "Epoch 74/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0925\n",
            "Epoch 75/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0920\n",
            "Epoch 76/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0918\n",
            "Epoch 77/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0925\n",
            "Epoch 78/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0918\n",
            "Epoch 79/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0918\n",
            "Epoch 80/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0920\n",
            "Epoch 81/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0920\n",
            "Epoch 82/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0923\n",
            "Epoch 83/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0920\n",
            "Epoch 84/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0921\n",
            "Epoch 85/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0906\n",
            "Epoch 86/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0923\n",
            "Epoch 87/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0924\n",
            "Epoch 88/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0918\n",
            "Epoch 89/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0911\n",
            "Epoch 90/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0922\n",
            "Epoch 91/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0918\n",
            "Epoch 92/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0913\n",
            "Epoch 93/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0923\n",
            "Epoch 94/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0921\n",
            "Epoch 95/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0916\n",
            "Epoch 96/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0902\n",
            "Epoch 97/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0925\n",
            "Epoch 98/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0925\n",
            "Epoch 99/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0917\n",
            "Epoch 100/100\n",
            "100/100 [==============================] - 0s 1ms/step - loss: 0.0921\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0900\n",
            "Final loss: 0.0900\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "Input: [0.5488135  0.71518937], Target: 3.55, Predicted: 3.81\n",
            "Input: [0.60276338 0.54488318], Target: 3.54, Predicted: 3.38\n",
            "Input: [0.4236548  0.64589411], Target: 3.16, Predicted: 3.34\n",
            "Input: [0.43758721 0.891773  ], Target: 3.73, Predicted: 4.14\n",
            "Input: [0.96366276 0.38344152], Target: 3.10, Predicted: 3.59\n",
            "Input: [0.79172504 0.52889492], Target: 3.24, Predicted: 3.71\n",
            "Input: [0.56804456 0.92559664], Target: 4.59, Predicted: 4.51\n",
            "Input: [0.07103606 0.0871293 ], Target: 0.86, Predicted: 0.88\n",
            "Input: [0.0202184  0.83261985], Target: 3.07, Predicted: 3.12\n",
            "Input: [0.77815675 0.87001215], Target: 5.06, Predicted: 4.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the Neural Network\n",
        "\n",
        "#with no hidden layer\n",
        "model = Sequential()\n",
        "model.add(normalizer)\n",
        "model.add(layers.Dense(units = 3, activation = 'softmax'))\n",
        "\n",
        "# Compile Neural Network\n",
        "model.compile(loss = \"categorical_crossentropy\",optimizer = \"sgd\",metrics = [\"accuracy\"])\n",
        "model.summary()\n",
        "# Train Model\n",
        "history = model.fit(X_train,y_train,epochs = 10,batch_size = 1,validation_data = (X_test, y_test))\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "Test_loss.append(loss)\n",
        "Test_accuracy.append(accuracy)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_train, y_train)\n",
        "Train_loss.append(loss)\n",
        "Train_accuracy.append(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHk7fbkKFdhq",
        "outputId": "d61a48e3-7d6d-4134-fd91-86263c38f6ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " normalization (Normalizati  (None, 5)                 11        \n",
            " on)                                                             \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 29 (120.00 Byte)\n",
            "Trainable params: 18 (72.00 Byte)\n",
            "Non-trainable params: 11 (48.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "120/120 [==============================] - 1s 3ms/step - loss: 0.7184 - accuracy: 0.6583 - val_loss: 0.6131 - val_accuracy: 0.5667\n",
            "Epoch 2/10\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7667 - val_loss: 0.5012 - val_accuracy: 0.6667\n",
            "Epoch 3/10\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.8417 - val_loss: 0.4366 - val_accuracy: 0.8000\n",
            "Epoch 4/10\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.3540 - accuracy: 0.9000 - val_loss: 0.3888 - val_accuracy: 0.8667\n",
            "Epoch 5/10\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.3149 - accuracy: 0.9167 - val_loss: 0.3567 - val_accuracy: 0.9000\n",
            "Epoch 6/10\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.2859 - accuracy: 0.9417 - val_loss: 0.3288 - val_accuracy: 0.9333\n",
            "Epoch 7/10\n",
            "120/120 [==============================] - 0s 2ms/step - loss: 0.2629 - accuracy: 0.9583 - val_loss: 0.3064 - val_accuracy: 0.9667\n",
            "Epoch 8/10\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2441 - accuracy: 0.9583 - val_loss: 0.2857 - val_accuracy: 0.9667\n",
            "Epoch 9/10\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2284 - accuracy: 0.9583 - val_loss: 0.2692 - val_accuracy: 0.9667\n",
            "Epoch 10/10\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.2150 - accuracy: 0.9750 - val_loss: 0.2547 - val_accuracy: 0.9667\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.2547 - accuracy: 0.9667\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2076 - accuracy: 0.9750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "# Generate some random data for demonstration\n",
        "np.random.seed(0)\n",
        "X = np.random.rand(100, 2)\n",
        "y = 2 * X[:, 0] + 3 * X[:, 1] + np.random.rand(100)\n",
        "\n",
        "# Create a simple neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(1, input_dim=2, activation='linear'))\n",
        "\n",
        "# Compile the model with SGD optimizer and a specified batch size\n",
        "batch_size = 16  # You can adjust the batch size\n",
        "sgd = SGD(learning_rate=0.01)  # You can adjust the learning rate\n",
        "model.compile(optimizer=sgd, loss='mean_squared_error')\n",
        "\n",
        "# Train the model using Mini-Batch SGD\n",
        "model.fit(X, y, epochs=100, batch_size=batch_size)\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X, y)\n",
        "print(f\"Final loss: {loss:.4f}\")\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(X)\n",
        "\n",
        "# Print some predictions\n",
        "for i in range(10):\n",
        "    print(f\"Input: {X[i]}, Target: {y[i]:.2f}, Predicted: {predictions[i][0]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pW3GJj7Fgcy",
        "outputId": "e822582e-47ef-4be8-993e-f09ef55fc8ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 8.7490\n",
            "Epoch 2/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 5.8582\n",
            "Epoch 3/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 4.0949\n",
            "Epoch 4/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 2.8671\n",
            "Epoch 5/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 2.0640\n",
            "Epoch 6/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 1.5152\n",
            "Epoch 7/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 1.1867\n",
            "Epoch 8/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.9466\n",
            "Epoch 9/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.7817\n",
            "Epoch 10/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.6870\n",
            "Epoch 11/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.6247\n",
            "Epoch 12/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5839\n",
            "Epoch 13/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.5527\n",
            "Epoch 14/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.5294\n",
            "Epoch 15/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.5090\n",
            "Epoch 16/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4948\n",
            "Epoch 17/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.4830\n",
            "Epoch 18/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.4740\n",
            "Epoch 19/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.4645\n",
            "Epoch 20/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.4564\n",
            "Epoch 21/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.4500\n",
            "Epoch 22/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.4431\n",
            "Epoch 23/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.4377\n",
            "Epoch 24/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.4312\n",
            "Epoch 25/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.4249\n",
            "Epoch 26/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.4203\n",
            "Epoch 27/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.4143\n",
            "Epoch 28/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.4085\n",
            "Epoch 29/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.4034\n",
            "Epoch 30/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.3988\n",
            "Epoch 31/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.3938\n",
            "Epoch 32/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.3888\n",
            "Epoch 33/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.3839\n",
            "Epoch 34/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.3800\n",
            "Epoch 35/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.3747\n",
            "Epoch 36/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.3701\n",
            "Epoch 37/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3652\n",
            "Epoch 38/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.3595\n",
            "Epoch 39/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3549\n",
            "Epoch 40/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3510\n",
            "Epoch 41/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3469\n",
            "Epoch 42/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.3416\n",
            "Epoch 43/100\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.3379\n",
            "Epoch 44/100\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.3331\n",
            "Epoch 45/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3292\n",
            "Epoch 46/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3264\n",
            "Epoch 47/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.3225\n",
            "Epoch 48/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.3179\n",
            "Epoch 49/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3146\n",
            "Epoch 50/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.3109\n",
            "Epoch 51/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.3075\n",
            "Epoch 52/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3039\n",
            "Epoch 53/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3004\n",
            "Epoch 54/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.2969\n",
            "Epoch 55/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.2939\n",
            "Epoch 56/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.2907\n",
            "Epoch 57/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.2875\n",
            "Epoch 58/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.2839\n",
            "Epoch 59/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.2809\n",
            "Epoch 60/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.2782\n",
            "Epoch 61/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.2749\n",
            "Epoch 62/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2714\n",
            "Epoch 63/100\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.2683\n",
            "Epoch 64/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.2654\n",
            "Epoch 65/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.2626\n",
            "Epoch 66/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.2601\n",
            "Epoch 67/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.2574\n",
            "Epoch 68/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.2544\n",
            "Epoch 69/100\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.2521\n",
            "Epoch 70/100\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.2491\n",
            "Epoch 71/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.2468\n",
            "Epoch 72/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.2439\n",
            "Epoch 73/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.2416\n",
            "Epoch 74/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.2388\n",
            "Epoch 75/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.2366\n",
            "Epoch 76/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.2340\n",
            "Epoch 77/100\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.2320\n",
            "Epoch 78/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2298\n",
            "Epoch 79/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.2276\n",
            "Epoch 80/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.2250\n",
            "Epoch 81/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.2231\n",
            "Epoch 82/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.2211\n",
            "Epoch 83/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.2191\n",
            "Epoch 84/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.2165\n",
            "Epoch 85/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.2147\n",
            "Epoch 86/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.2128\n",
            "Epoch 87/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.2106\n",
            "Epoch 88/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.2088\n",
            "Epoch 89/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.2072\n",
            "Epoch 90/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.2052\n",
            "Epoch 91/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.2039\n",
            "Epoch 92/100\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2018\n",
            "Epoch 93/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.1998\n",
            "Epoch 94/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.1985\n",
            "Epoch 95/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1965\n",
            "Epoch 96/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1948\n",
            "Epoch 97/100\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.1934\n",
            "Epoch 98/100\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.1918\n",
            "Epoch 99/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.1901\n",
            "Epoch 100/100\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.1887\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1876\n",
            "Final loss: 0.1876\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "Input: [0.5488135  0.71518937], Target: 3.55, Predicted: 3.57\n",
            "Input: [0.60276338 0.54488318], Target: 3.54, Predicted: 3.29\n",
            "Input: [0.4236548  0.64589411], Target: 3.16, Predicted: 3.23\n",
            "Input: [0.43758721 0.891773  ], Target: 3.73, Predicted: 3.77\n",
            "Input: [0.96366276 0.38344152], Target: 3.10, Predicted: 3.49\n",
            "Input: [0.79172504 0.52889492], Target: 3.24, Predicted: 3.54\n",
            "Input: [0.56804456 0.92559664], Target: 4.59, Predicted: 4.04\n",
            "Input: [0.07103606 0.0871293 ], Target: 0.86, Predicted: 1.52\n",
            "Input: [0.0202184  0.83261985], Target: 3.07, Predicted: 3.02\n",
            "Input: [0.77815675 0.87001215], Target: 5.06, Predicted: 4.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the Neural Network\n",
        "\n",
        "#with no hidden layer\n",
        "model = Sequential()\n",
        "model.add(normalizer)\n",
        "model.add(layers.Dense(units = 3, activation = 'softmax'))\n",
        "\n",
        "# Compile Neural Network\n",
        "model.compile(loss = \"categorical_crossentropy\",\n",
        "                optimizer = \"sgd\",\n",
        "                metrics = [\"accuracy\"]\n",
        "                )\n",
        "\n",
        "model.summary()\n",
        "# Train Model\n",
        "history = model.fit(X_train,y_train,epochs = 10,batch_size =2 ,validation_data = (X_test, y_test))\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "Test_loss.append(loss)\n",
        "Test_accuracy.append(accuracy)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_train, y_train)\n",
        "Train_loss.append(loss)\n",
        "Train_accuracy.append(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYGisuwPFg4q",
        "outputId": "6763739a-afc3-4fc8-bb38-65f3a4321147"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " normalization (Normalizati  (None, 5)                 11        \n",
            " on)                                                             \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 29 (120.00 Byte)\n",
            "Trainable params: 18 (72.00 Byte)\n",
            "Non-trainable params: 11 (48.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "60/60 [==============================] - 1s 5ms/step - loss: 0.6519 - accuracy: 0.7250 - val_loss: 0.5844 - val_accuracy: 0.8333\n",
            "Epoch 2/10\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.5220 - accuracy: 0.8250 - val_loss: 0.5301 - val_accuracy: 0.8333\n",
            "Epoch 3/10\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.8750 - val_loss: 0.4963 - val_accuracy: 0.7667\n",
            "Epoch 4/10\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.8750 - val_loss: 0.4701 - val_accuracy: 0.7667\n",
            "Epoch 5/10\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3889 - accuracy: 0.8750 - val_loss: 0.4469 - val_accuracy: 0.7667\n",
            "Epoch 6/10\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8833 - val_loss: 0.4274 - val_accuracy: 0.7667\n",
            "Epoch 7/10\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3453 - accuracy: 0.8833 - val_loss: 0.4085 - val_accuracy: 0.8667\n",
            "Epoch 8/10\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8833 - val_loss: 0.3922 - val_accuracy: 0.9000\n",
            "Epoch 9/10\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3135 - accuracy: 0.9083 - val_loss: 0.3770 - val_accuracy: 0.9000\n",
            "Epoch 10/10\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3004 - accuracy: 0.9083 - val_loss: 0.3625 - val_accuracy: 0.9000\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.3625 - accuracy: 0.9000\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2931 - accuracy: 0.9167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the Neural Network\n",
        "\n",
        "#with no hidden layer\n",
        "model = Sequential()\n",
        "model.add(normalizer)\n",
        "model.add(layers.Dense(units = 3, activation = 'softmax'))\n",
        "\n",
        "# Compile Neural Network\n",
        "model.compile(loss = \"categorical_crossentropy\",\n",
        "                optimizer = \"sgd\",\n",
        "                metrics = [\"accuracy\"]\n",
        "                )\n",
        "\n",
        "model.summary()\n",
        "# Train Model\n",
        "history = model.fit(X_train,y_train,epochs = 10,batch_size =4 ,validation_data = (X_test, y_test))\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "Test_loss.append(loss)\n",
        "Test_accuracy.append(accuracy)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_train, y_train)\n",
        "Train_loss.append(loss)\n",
        "Train_accuracy.append(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXo4L1-iFkSK",
        "outputId": "a3ec28b5-5ba5-4b46-a2ab-18140dfb109d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " normalization (Normalizati  (None, 5)                 11        \n",
            " on)                                                             \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 29 (120.00 Byte)\n",
            "Trainable params: 18 (72.00 Byte)\n",
            "Non-trainable params: 11 (48.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "30/30 [==============================] - 1s 8ms/step - loss: 0.5742 - accuracy: 0.7167 - val_loss: 0.6332 - val_accuracy: 0.6000\n",
            "Epoch 2/10\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.5349 - accuracy: 0.7667 - val_loss: 0.5992 - val_accuracy: 0.6333\n",
            "Epoch 3/10\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.5031 - accuracy: 0.7833 - val_loss: 0.5707 - val_accuracy: 0.6667\n",
            "Epoch 4/10\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4761 - accuracy: 0.7917 - val_loss: 0.5462 - val_accuracy: 0.7000\n",
            "Epoch 5/10\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4530 - accuracy: 0.8000 - val_loss: 0.5249 - val_accuracy: 0.7333\n",
            "Epoch 6/10\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4331 - accuracy: 0.8083 - val_loss: 0.5057 - val_accuracy: 0.7667\n",
            "Epoch 7/10\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.4153 - accuracy: 0.8333 - val_loss: 0.4888 - val_accuracy: 0.7667\n",
            "Epoch 8/10\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3996 - accuracy: 0.8750 - val_loss: 0.4733 - val_accuracy: 0.7667\n",
            "Epoch 9/10\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3856 - accuracy: 0.8917 - val_loss: 0.4592 - val_accuracy: 0.7667\n",
            "Epoch 10/10\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.3727 - accuracy: 0.9083 - val_loss: 0.4459 - val_accuracy: 0.7667\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.4459 - accuracy: 0.7667\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3657 - accuracy: 0.9167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the Neural Network\n",
        "\n",
        "#with no hidden layer\n",
        "model = Sequential()\n",
        "model.add(normalizer)\n",
        "model.add(layers.Dense(units = 3, activation = 'softmax'))\n",
        "\n",
        "# Compile Neural Network\n",
        "model.compile(loss = \"categorical_crossentropy\",\n",
        "                optimizer = \"sgd\",\n",
        "                metrics = [\"accuracy\"]\n",
        "                )\n",
        "\n",
        "model.summary()\n",
        "# Train Model\n",
        "history = model.fit(X_train,y_train,epochs = 10,batch_size =16 ,validation_data = (X_test, y_test))\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "Test_loss.append(loss)\n",
        "Test_accuracy.append(accuracy)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_train, y_train)\n",
        "Train_loss.append(loss)\n",
        "Train_accuracy.append(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1IGPA2tFm5q",
        "outputId": "64c7e272-b630-4a21-e0ef-b4313c2a8eac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " normalization (Normalizati  (None, 5)                 11        \n",
            " on)                                                             \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 29 (120.00 Byte)\n",
            "Trainable params: 18 (72.00 Byte)\n",
            "Non-trainable params: 11 (48.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "8/8 [==============================] - 1s 41ms/step - loss: 1.5052 - accuracy: 0.2500 - val_loss: 1.4401 - val_accuracy: 0.4000\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.3800 - accuracy: 0.3250 - val_loss: 1.3451 - val_accuracy: 0.4333\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.2735 - accuracy: 0.4417 - val_loss: 1.2625 - val_accuracy: 0.4333\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.1805 - accuracy: 0.4583 - val_loss: 1.1918 - val_accuracy: 0.4667\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.1012 - accuracy: 0.4750 - val_loss: 1.1291 - val_accuracy: 0.4667\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0319 - accuracy: 0.5083 - val_loss: 1.0744 - val_accuracy: 0.4667\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9707 - accuracy: 0.5500 - val_loss: 1.0262 - val_accuracy: 0.5000\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.9184 - accuracy: 0.5667 - val_loss: 0.9827 - val_accuracy: 0.5333\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.8712 - accuracy: 0.5833 - val_loss: 0.9442 - val_accuracy: 0.5333\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.8290 - accuracy: 0.5917 - val_loss: 0.9098 - val_accuracy: 0.5333\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.9098 - accuracy: 0.5333\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8059 - accuracy: 0.6250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the Neural Network\n",
        "\n",
        "#with no hidden layer\n",
        "model = Sequential()\n",
        "model.add(normalizer)\n",
        "model.add(layers.Dense(units = 3, activation = 'softmax'))\n",
        "\n",
        "# Compile Neural Network\n",
        "model.compile(loss = \"categorical_crossentropy\",\n",
        "                optimizer = \"sgd\",\n",
        "                metrics = [\"accuracy\"]\n",
        "                )\n",
        "\n",
        "model.summary()\n",
        "# Train Model\n",
        "history = model.fit(X_train,y_train,epochs = 10,batch_size =32 ,validation_data = (X_test, y_test))\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "Test_loss.append(loss)\n",
        "Test_accuracy.append(accuracy)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_train, y_train)\n",
        "Train_loss.append(loss)\n",
        "Train_accuracy.append(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jo0yBbrFobZ",
        "outputId": "ed9a96c3-b1fe-45c8-83e2-f5bfc455ada8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " normalization (Normalizati  (None, 5)                 11        \n",
            " on)                                                             \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 29 (120.00 Byte)\n",
            "Trainable params: 18 (72.00 Byte)\n",
            "Non-trainable params: 11 (48.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 1s 69ms/step - loss: 1.0456 - accuracy: 0.4667 - val_loss: 1.2714 - val_accuracy: 0.3333\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 1.0104 - accuracy: 0.4750 - val_loss: 1.2263 - val_accuracy: 0.3333\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9786 - accuracy: 0.4833 - val_loss: 1.1822 - val_accuracy: 0.3333\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9477 - accuracy: 0.5000 - val_loss: 1.1409 - val_accuracy: 0.3667\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9194 - accuracy: 0.5167 - val_loss: 1.1029 - val_accuracy: 0.3667\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.8934 - accuracy: 0.5583 - val_loss: 1.0672 - val_accuracy: 0.4000\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8691 - accuracy: 0.5667 - val_loss: 1.0333 - val_accuracy: 0.4000\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8460 - accuracy: 0.5917 - val_loss: 1.0023 - val_accuracy: 0.4333\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8251 - accuracy: 0.6250 - val_loss: 0.9729 - val_accuracy: 0.4333\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8053 - accuracy: 0.6333 - val_loss: 0.9461 - val_accuracy: 0.4667\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.9461 - accuracy: 0.4667\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7932 - accuracy: 0.6583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Sequential()\n",
        "model.add(normalizer)\n",
        "model.add(layers.Dense(units = 3, activation = 'softmax'))\n",
        "\n",
        "# Compile Neural Network\n",
        "model.compile(loss = \"categorical_crossentropy\",\n",
        "                optimizer = \"sgd\",\n",
        "                metrics = [\"accuracy\"]\n",
        "                )\n",
        "\n",
        "model.summary()\n",
        "# Train Model\n",
        "history = model.fit(X_train,y_train,epochs = 10,batch_size =len(X_train),validation_data = (X_test, y_test))\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "Test_loss.append(loss)\n",
        "Test_accuracy.append(accuracy)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_train, y_train)\n",
        "Train_loss.append(loss)\n",
        "Train_accuracy.append(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alpO3lDvFxsy",
        "outputId": "fbd48a21-fea6-4691-e7fb-1cd0ddafd3c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " normalization (Normalizati  (None, 5)                 11        \n",
            " on)                                                             \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 29 (120.00 Byte)\n",
            "Trainable params: 18 (72.00 Byte)\n",
            "Non-trainable params: 11 (48.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 533ms/step - loss: 1.1993 - accuracy: 0.3250 - val_loss: 1.4213 - val_accuracy: 0.3333\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.1847 - accuracy: 0.3500 - val_loss: 1.4062 - val_accuracy: 0.3333\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.1705 - accuracy: 0.3583 - val_loss: 1.3913 - val_accuracy: 0.3333\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.1565 - accuracy: 0.3667 - val_loss: 1.3767 - val_accuracy: 0.3333\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.1428 - accuracy: 0.3667 - val_loss: 1.3624 - val_accuracy: 0.3333\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.1293 - accuracy: 0.3750 - val_loss: 1.3483 - val_accuracy: 0.3333\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.1161 - accuracy: 0.3750 - val_loss: 1.3344 - val_accuracy: 0.3333\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.1032 - accuracy: 0.3833 - val_loss: 1.3207 - val_accuracy: 0.3667\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.0905 - accuracy: 0.3917 - val_loss: 1.3073 - val_accuracy: 0.3667\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 1.0781 - accuracy: 0.3917 - val_loss: 1.2941 - val_accuracy: 0.4000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.2941 - accuracy: 0.4000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0659 - accuracy: 0.3917\n"
          ]
        }
      ]
    }
  ]
}